{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pipeline-notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rawar/ix-ml-pydeequ/blob/main/pipeline_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyDeequ ML-Pipeline\n",
        "\n",
        "Innerhalb dieses Notebooks wird die Anwendung von PyDeequ für die Prüfung der Datenqualität innerhalb einer einfachen Machine Learning Pipeline gezeigt."
      ],
      "metadata": {
        "id": "4pmDrqzcwXFc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Java, Hadoop, Spark und PyDeequ installieren"
      ],
      "metadata": {
        "id": "MnKEOcCr4Ilt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dveOCDuGwJzX"
      },
      "outputs": [],
      "source": [
        "# Notebook-Umgebung auf den neusten Stand bringen\n",
        "!apt-get -qq update"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Java installieren\n",
        "!apt-get -qq install -y openjdk-8-jdk-headless\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "!java -version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRcojA5KwgJH",
        "outputId": "8b4d9cd6-99bc-412e-8869-5aea59ae64ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "(Reading database ... 155229 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u312-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u312-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u312-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n",
            "openjdk version \"1.8.0_312\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_312-8u312-b07-0ubuntu1~18.04-b07)\n",
            "OpenJDK 64-Bit Server VM (build 25.312-b07, mixed mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Spark und Hadoop herunterladen. Verschiedene Versionen finden sich unter https://archive.apache.org/dist/spark/spark-2.4.7/\n",
        "!wget  https://archive.apache.org/dist/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2dgjqE0wof_",
        "outputId": "a3efc547-c77d-46ce-9007-d0335a9ebe51"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-30 14:51:19--  https://archive.apache.org/dist/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz\n",
            "Resolving archive.apache.org (archive.apache.org)... 138.201.131.134, 2a01:4f8:172:2ec5::2\n",
            "Connecting to archive.apache.org (archive.apache.org)|138.201.131.134|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 227893062 (217M) [application/x-gzip]\n",
            "Saving to: ‘spark-2.4.0-bin-hadoop2.7.tgz’\n",
            "\n",
            "spark-2.4.0-bin-had 100%[===================>] 217.33M  24.4MB/s    in 9.5s    \n",
            "\n",
            "2022-01-30 14:51:29 (22.9 MB/s) - ‘spark-2.4.0-bin-hadoop2.7.tgz’ saved [227893062/227893062]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Spark und Hadoop installieren\n",
        "!tar xf spark-2.4.0-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "ZCow69qQwsr7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Umgebungsvariablen setzen\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.0-bin-hadoop2.7\"\n",
        "os.environ[\"SPARK_VERSION\"] = \"2.4.0\""
      ],
      "metadata": {
        "id": "JrVnnR_ywzCt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spark initialisieren\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "9eGFvcfhw0Pz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyDeequ installieren\n",
        "!pip install pydeequ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vULPDcTw2-S",
        "outputId": "14ee346f-2781-49b2-b054-5f659cfd9369"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydeequ in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from pydeequ) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.7/dist-packages (from pydeequ) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->pydeequ) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->pydeequ) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.0->pydeequ) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Beispieldatensatz laden\n",
        "Innerhalb dieses Notebooks werden Daten von Amazon Video Game Reviews aus dem Jahre 2014 verwendet, welche für Testzwecke von der UCSD zur Verfügung gestellt werden und [hier]http://deepyeti.ucsd.edu/jianmo/amazon/) heruntergeladen werden können. "
      ],
      "metadata": {
        "id": "EezPJWZyxcwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Herunterladen der Review Daten\n",
        "!wget http://deepyeti.ucsd.edu/jianmo/amazon/categoryFiles/Video_Games.json.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQScwreHxnoQ",
        "outputId": "a3939c90-9c48-4859-f042-fc19fe093691"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-30 14:51:53--  http://deepyeti.ucsd.edu/jianmo/amazon/categoryFiles/Video_Games.json.gz\n",
            "Resolving deepyeti.ucsd.edu (deepyeti.ucsd.edu)... 169.228.63.50\n",
            "Connecting to deepyeti.ucsd.edu (deepyeti.ucsd.edu)|169.228.63.50|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 522823613 (499M) [application/octet-stream]\n",
            "Saving to: ‘Video_Games.json.gz’\n",
            "\n",
            "Video_Games.json.gz 100%[===================>] 498.60M  50.2MB/s    in 10s     \n",
            "\n",
            "2022-01-30 14:52:03 (48.7 MB/s) - ‘Video_Games.json.gz’ saved [522823613/522823613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Auspacken der Review Daten\n",
        "!gunzip Video_Games.json.gz"
      ],
      "metadata": {
        "id": "i0dp1HljBi6B"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import gzip\n",
        "import pandas as pd\n",
        "import pydeequ\n",
        "from time import time\n",
        "from pyspark.sql import SparkSession, Row\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.ml.feature import StringIndexer, IndexToString\n",
        "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit,CrossValidator\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml import Pipeline, PipelineModel"
      ],
      "metadata": {
        "id": "C-cTaJVwzTCq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spark Session konfigurieren und initialisieren \n",
        "spark = SparkSession.builder.master(\"local\").appName(\"Colab\").config('spark.ui.port', '4050').config(\"spark.jars.packages\", pydeequ.deequ_maven_coord).config(\"spark.jars.excludes\", pydeequ.f2j_maven_coord).getOrCreate()\n",
        "conf = spark.sparkContext._conf.setAll([('spark.executor.memory', '8g'), ('spark.driver.memory','8g')])"
      ],
      "metadata": {
        "id": "pBonYxDrw_7L"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Einlesen der Review Daten in Spark\n",
        "ddf = spark.read.json(\"Video_Games.json\")"
      ],
      "metadata": {
        "id": "URPh4BWu3HSb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Anzahl der Datensätze zählen\n",
        "ddf.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-CbN7pwB0Jn",
        "outputId": "b2695d64-2e13-4cfe-9eca-49cdd292c0bf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2565349"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drei Beispieldatensätze anzeigen\n",
        "ddf.show(n=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEq5wuQxByUb",
        "outputId": "a838dce7-de6f-4fbc-f3ff-41a5b878cdc0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-------+--------------------+-----------+--------------+---------------+-----+--------------------+--------------+--------+----+\n",
            "|      asin|image|overall|          reviewText| reviewTime|    reviewerID|   reviewerName|style|             summary|unixReviewTime|verified|vote|\n",
            "+----------+-----+-------+--------------------+-----------+--------------+---------------+-----+--------------------+--------------+--------+----+\n",
            "|0439381673| null|    1.0|I used to play th...| 06 9, 2014|A21ROB4YDOZA5P|  Mary M. Clark| null|   Did not like this|    1402272000|    true|null|\n",
            "|0439381673| null|    3.0|The game itself w...|05 10, 2014|A3TNZ2Q5E7HTHD|      Sarabatya| null|      Almost Perfect|    1399680000|    true|null|\n",
            "|0439381673| null|    4.0|I had to learn th...| 02 7, 2014|A1OKRM3QFEATQO|Amazon Customer| null|DOES NOT WORK WIT...|    1391731200|    true|  15|\n",
            "+----------+-----+-------+--------------------+-----------+--------------+---------------+-----+--------------------+--------------+--------+----+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rohdaten auswählen"
      ],
      "metadata": {
        "id": "alXUOa0TC9gB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unwichtige Spalten löschen\n",
        "ddf = ddf.drop('helpful','reviewText','reviewTime','reviewerName','unixReviewTime','summary')"
      ],
      "metadata": {
        "id": "RuBWyKtuB-fQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spalten umbenennen\n",
        "ddf = ddf.selectExpr(\"asin\",\"overall as rating\", \"reviewerID as user\")"
      ],
      "metadata": {
        "id": "-NUf2IA-CloA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drei Beispieldatensätze anzeigen\n",
        "ddf.show(n=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EWBw32jCNRl",
        "outputId": "cfcd42be-898b-4059-9f9d-16607e521b5c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------+--------------+\n",
            "|      asin|rating|          user|\n",
            "+----------+------+--------------+\n",
            "|0439381673|   1.0|A21ROB4YDOZA5P|\n",
            "|0439381673|   3.0|A3TNZ2Q5E7HTHD|\n",
            "|0439381673|   4.0|A1OKRM3QFEATQO|\n",
            "+----------+------+--------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Datensatz verkleinern\n",
        "ddf = ddf.sample(0.01)"
      ],
      "metadata": {
        "id": "1u4-1faESYz0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Datensatzgröße: {ddf.count()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc7G_yK8Sgs9",
        "outputId": "650f6b13-fa93-4a04-e103-a4338854cac7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datensatzgröße: 25449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Daten verifizieren\n",
        "\n",
        "PyDeequ kann im ersten Schritt einige statistische Daten zu dem zu verarbeitenden Datensatz erstellen. Deequ kennt eine Reihe dieser statistischen Metriken (metrics). Einen guten Überblick findet sich [hier](https://aws.amazon.com/de/blogs/big-data/test-data-quality-at-scale-with-deequ/). Im Quellcode findet man die Metriken [hier](https://github.com/awslabs/deequ/tree/master/src/main/scala/com/amazon/deequ/analyzers). "
      ],
      "metadata": {
        "id": "cyANegsnDLI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydeequ.analyzers import *\n",
        "from pydeequ.profiles import *\n",
        "from pydeequ.suggestions import *\n",
        "from pydeequ.checks import *\n",
        "from pydeequ.verification import *\n",
        "from pydeequ.repository import *"
      ],
      "metadata": {
        "id": "a25NLCB6xS6g"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analysisResult = AnalysisRunner(spark) \\\n",
        "  .onData(ddf) \\\n",
        "  .addAnalyzer(Size()) \\\n",
        "  .addAnalyzer(Completeness(\"user\")) \\\n",
        "  .addAnalyzer(ApproxCountDistinct(\"user\")) \\\n",
        "  .addAnalyzer(Mean(\"rating\")) \\\n",
        "  .addAnalyzer(Compliance(\"top rating\", \"rating >= 4.0\")) \\\n",
        "  .addAnalyzer(Correlation(\"total_rating\", \"top rating\")) \\\n",
        "  .run()"
      ],
      "metadata": {
        "id": "8tuVgQwSxT-w"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analysisResult_df = AnalyzerContext.successMetricsAsDataFrame(spark, analysisResult)\n",
        "analysisResult_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fx5HdktuxZUJ",
        "outputId": "a2f0c0ab-dad7-4ae0-ebd4-e39c33856fb2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-------------------+------------------+\n",
            "| entity|  instance|               name|             value|\n",
            "+-------+----------+-------------------+------------------+\n",
            "| Column|    rating|               Mean|4.0189240577989995|\n",
            "| Column|      user|       Completeness|               1.0|\n",
            "| Column|      user|ApproxCountDistinct|          250142.0|\n",
            "|Dataset|         *|               Size|          256129.0|\n",
            "| Column|top rating|         Compliance|0.7400294382908612|\n",
            "+-------+----------+-------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aus dem Ergebnis lässt sich ablesen, dass wir 2.4 Mio Datensätze haben und das wir ein Durchschnittliches Rating von 4 Sternen haben. "
      ],
      "metadata": {
        "id": "e8ljhKaHLIL8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Automatische Vorschläge für Contrains erzeugen"
      ],
      "metadata": {
        "id": "91gMjrNXP0gY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "suggestionResult = ConstraintSuggestionRunner(spark) \\\n",
        "  .onData(ddf) \\\n",
        "  .addConstraintRule(DEFAULT()) \\\n",
        "  .run()\n",
        "\n",
        "# Constraint Suggestions in JSON format\n",
        "print(json.dumps(suggestionResult, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLFvsXOuQG9Y",
        "outputId": "69ff789a-20b7-4d9c-ec88-165d4caafbfd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"constraint_suggestions\": [\n",
            "    {\n",
            "      \"constraint_name\": \"CompletenessConstraint(Completeness(rating,None))\",\n",
            "      \"column_name\": \"rating\",\n",
            "      \"current_value\": \"Completeness: 1.0\",\n",
            "      \"description\": \"'rating' is not null\",\n",
            "      \"suggesting_rule\": \"CompleteIfCompleteRule()\",\n",
            "      \"rule_description\": \"If a column is complete in the sample, we suggest a NOT NULL constraint\",\n",
            "      \"code_for_constraint\": \".isComplete(\\\"rating\\\")\"\n",
            "    },\n",
            "    {\n",
            "      \"constraint_name\": \"ComplianceConstraint(Compliance('rating' has no negative values,rating >= 0,None))\",\n",
            "      \"column_name\": \"rating\",\n",
            "      \"current_value\": \"Minimum: 1.0\",\n",
            "      \"description\": \"'rating' has no negative values\",\n",
            "      \"suggesting_rule\": \"NonNegativeNumbersRule()\",\n",
            "      \"rule_description\": \"If we see only non-negative numbers in a column, we suggest a corresponding constraint\",\n",
            "      \"code_for_constraint\": \".isNonNegative(\\\"rating\\\")\"\n",
            "    },\n",
            "    {\n",
            "      \"constraint_name\": \"CompletenessConstraint(Completeness(user,None))\",\n",
            "      \"column_name\": \"user\",\n",
            "      \"current_value\": \"Completeness: 1.0\",\n",
            "      \"description\": \"'user' is not null\",\n",
            "      \"suggesting_rule\": \"CompleteIfCompleteRule()\",\n",
            "      \"rule_description\": \"If a column is complete in the sample, we suggest a NOT NULL constraint\",\n",
            "      \"code_for_constraint\": \".isComplete(\\\"user\\\")\"\n",
            "    },\n",
            "    {\n",
            "      \"constraint_name\": \"UniquenessConstraint(Uniqueness(List(user),None))\",\n",
            "      \"column_name\": \"user\",\n",
            "      \"current_value\": \"ApproxDistinctness: 0.976625060028345\",\n",
            "      \"description\": \"'user' is unique\",\n",
            "      \"suggesting_rule\": \"UniqueIfApproximatelyUniqueRule()\",\n",
            "      \"rule_description\": \"If the ratio of approximate num distinct values in a column is close to the number of records (within the error of the HLL sketch), we suggest a UNIQUE constraint\",\n",
            "      \"code_for_constraint\": \".isUnique(\\\"user\\\")\"\n",
            "    },\n",
            "    {\n",
            "      \"constraint_name\": \"CompletenessConstraint(Completeness(asin,None))\",\n",
            "      \"column_name\": \"asin\",\n",
            "      \"current_value\": \"Completeness: 1.0\",\n",
            "      \"description\": \"'asin' is not null\",\n",
            "      \"suggesting_rule\": \"CompleteIfCompleteRule()\",\n",
            "      \"rule_description\": \"If a column is complete in the sample, we suggest a NOT NULL constraint\",\n",
            "      \"code_for_constraint\": \".isComplete(\\\"asin\\\")\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testen der Daten"
      ],
      "metadata": {
        "id": "aWnjk9wMLzPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check = Check(spark, CheckLevel.Warning, \"Video Game Review Check\")"
      ],
      "metadata": {
        "id": "5d1V77V2L6f8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkResult = VerificationSuite(spark) \\\n",
        "  .onData(ddf) \\\n",
        "  .addCheck(\n",
        "    check.hasSize(lambda x: x >= 2000000) \\\n",
        "      .hasMin(\"rating\", lambda x: x == 1.0) \\\n",
        "      .hasMax(\"rating\", lambda x: x == 5.0)  \\\n",
        "      .isComplete(\"user\")  \\\n",
        "      .isUnique(\"user\")  \\\n",
        "  ).run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udNINUh0MIJD",
        "outputId": "5b0dab4a-b08c-4890-947a-4cf5223fb785"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python Callback server started!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
        "checkResult_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeyD78YvPCtK",
        "outputId": "09652e73-bccf-42ff-9b70-603fb6521297"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------+------------+--------------------+-----------------+--------------------+\n",
            "|               check|check_level|check_status|          constraint|constraint_status|  constraint_message|\n",
            "+--------------------+-----------+------------+--------------------+-----------------+--------------------+\n",
            "|Video Game Review...|    Warning|     Warning|SizeConstraint(Si...|          Failure|Value: 256129 doe...|\n",
            "|Video Game Review...|    Warning|     Warning|MinimumConstraint...|          Success|                    |\n",
            "|Video Game Review...|    Warning|     Warning|MaximumConstraint...|          Success|                    |\n",
            "|Video Game Review...|    Warning|     Warning|CompletenessConst...|          Success|                    |\n",
            "|Video Game Review...|    Warning|     Warning|UniquenessConstra...|          Failure|Value: 0.80698398...|\n",
            "+--------------------+-----------+------------+--------------------+-----------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datenaufbereiten für Collaboratives Filtering mit Alternating Least Squares (ALS)\n",
        "\n",
        "[Quelle](https://github.com/craigmacartney/Spark-ALS-Recommendation/blob/master/AmazonRecommendationSystem.ipynb)"
      ],
      "metadata": {
        "id": "cTRFVwT7EJ3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Umwandlen der asin und user Spalte von einem String in einen StringIndexer \n",
        "asinIndexer = StringIndexer(inputCol=\"asin\", outputCol=\"item\",handleInvalid='error') \n",
        "userIndexer = StringIndexer(inputCol='user',outputCol='userid',handleInvalid='error') \n",
        "asinIndexed = asinIndexer.fit(ddf).transform(ddf) # \n",
        "userIndexed = userIndexer.fit(asinIndexed).transform(asinIndexed) \n",
        "ddf_indexed = userIndexed.drop('asin').drop('user') "
      ],
      "metadata": {
        "id": "8Y364bLTES_P"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 80:10 Aufteilung für Training- und Testdaten\n",
        "(ddf_train, ddf_test) = ddf_indexed.randomSplit([0.8,0.2])\n",
        "ddf_train.cache() \n",
        "ddf_test.cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8JdL0CuFr_o",
        "outputId": "c94ca38a-3c60-4efe-f0f6-2b592b6246bb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[rating: double, item: double, userid: double]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Größe des Trainings- und Testdatensatzes\n",
        "print(f\"Train set size: {ddf_train.count()}\")\n",
        "print(f\"Test set size: {ddf_test.count()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nz1b6lDgFxkp",
        "outputId": "f810ccbd-524a-46c0-da00-b2e397f2a7f1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 20405\n",
            "Test set size: 5044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Matrixgröße, Prozentsatz der gefüllten Matrix und Anzahl der verschiedenen Nutzer und Items:')\n",
        "ddf_train.createOrReplaceTempView('ddf_train')\n",
        "spark.sql(\"\"\"\n",
        "      SELECT *, 100 * rating/matrix_size AS percentage\n",
        "        FROM (\n",
        "          SELECT userid, item, rating, userid * item AS matrix_size\n",
        "            FROM(\n",
        "              SELECT COUNT(*) AS rating, COUNT(DISTINCT(item)) AS item, COUNT(DISTINCT(userid)) AS userid\n",
        "                FROM ddf_train\n",
        "                )\n",
        "            )\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tfHFVM5F5Z6",
        "outputId": "56a29067-03d3-42d0-9f7c-507ad414e43b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix size, percentage of matrix filled and number of distinct users and itmes:\n",
            "+------+-----+------+-----------+--------------------+\n",
            "|userid| item|rating|matrix_size|          percentage|\n",
            "+------+-----+------+-----------+--------------------+\n",
            "|184102|32420|204695| 5968586840|0.003429538775044446|\n",
            "+------+-----+------+-----------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recommender Modell trainieren"
      ],
      "metadata": {
        "id": "tD0CaaqHWDxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modell erzeugen\n",
        "als = ALS(userCol=\"userid\", itemCol=\"item\", ratingCol=\"rating\",coldStartStrategy='drop',nonnegative=False)"
      ],
      "metadata": {
        "id": "exrwJVw2WH-7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluator erzeugen\n",
        "rmseevaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")"
      ],
      "metadata": {
        "id": "ZQ8pLDdoWObI"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter Grid erzeugen\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "  .addGrid(als.rank, [1,5,10,50,70]) \\\n",
        "  .addGrid(als.maxIter,[15]) \\\n",
        "  .addGrid(als.regParam,[0.05,0.1,0.5,5]) \\\n",
        "  .build()"
      ],
      "metadata": {
        "id": "nOaFgUUJWTEQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aufteilung in Trainings- und Validierungsdaten \n",
        "tvs = TrainValidationSplit(estimator=als,\n",
        "  estimatorParamMaps=paramGrid,\n",
        "  evaluator=rmseevaluator,\n",
        "  trainRatio=0.8)\n",
        "\n",
        "# Model trainieren und die Trainingszeit messen\n",
        "startTime = time()\n",
        "tvsmodel = tvs.fit(ddf_train)\n",
        "endTime = time()\n",
        "measured_execution_time = (endTime-startTime)\n",
        "    \n",
        "print(f\"Gemessene Trainingszeit: {measured_execution_time}\")"
      ],
      "metadata": {
        "id": "PSYj7CBUWwyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vorhersage und Auswertung mit Hilfe des Testdatensatzes\n",
        "predictions = tvsmodel.transform(ddf_test)\n",
        "testset_rmse = rmseevaluator.evaluate(predictions)\n",
        "print(f\"Test set RMSE: {testset_rmse}\") "
      ],
      "metadata": {
        "id": "IrL8uxayXeBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recommender Modell anwenden"
      ],
      "metadata": {
        "id": "BDFhPARMbeXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommendVideoGames(model, user, num_rec):\n",
        "    itemsuser = ddf_train.select(\"item\").distinct().withColumn(\"userid\", lit(user))\n",
        "    gamesrated = ddf_train.filter(ddf_train.userid == user).select(\"item\", \"userid\")\n",
        "    predictions = model.transform(itemsuser.subtract(gamesrated)).dropna().orderBy(\"prediction\", ascending=False).limit(num_rec).select(\"item\", \"prediction\")\n",
        "    predictions.show()\n",
        "    converter = IndexToString(inputCol=\"item\", outputCol=\"originalCategory\")\n",
        "    converted = converter.transform(predictions)\n",
        "    converted.show()"
      ],
      "metadata": {
        "id": "Cb8DGIFLbHlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommendGrecommendVideoGamesames(tvsmodel,696,3)"
      ],
      "metadata": {
        "id": "GDPRpwqvbpe8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}